import os
import warnings
import time
from datetime import datetime
from faster_whisper import WhisperModel

warnings.filterwarnings("ignore")

# === è¨­å®šé …ç›® ===
SILENCE_THRESHOLD = 2.0  # ã“ã‚Œä»¥ä¸Šã®ç©ºç™½ãŒã‚ã‚Œã°ã€Œï¼ˆç„¡éŸ³ï¼‰ã€ã¨è¡¨ç¤ºã™ã‚‹ç§’æ•°
VAD_PARAMS = dict(
    min_silence_duration_ms=1000, # ã“ã‚Œã‚ˆã‚ŠçŸ­ã„ç„¡éŸ³ã¯ç„¡è¦–ï¼ˆä¼šè©±ã®é–“ã®ãƒãƒ¼ã‚ºã‚’åˆ‡ã‚‰ãªã„ï¼‰
    speech_pad_ms=500,            # éŸ³å£°ã®å‰å¾Œã«500msã®ä½™ç™½ã‚’æŒãŸã›ã‚‹ï¼ˆèªå°¾åˆ‡ã‚Œé˜²æ­¢ï¼‰
)
# =============

def format_timestamp(seconds):
    seconds = max(0, int(seconds))
    hours = seconds // 3600
    minutes = (seconds % 3600) // 60
    secs = seconds % 60
    if hours > 0:
        return f"{hours}:{minutes:02d}:{secs:02d}"
    else:
        return f"{minutes:02d}:{secs:02d}"


def transcribe_mp3_files():
    folder_path = os.path.dirname(os.path.abspath(__file__))

    print("ğŸ¤– faster-whisperãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
    model = WhisperModel(
        "medium",
        device="cpu",          # GPUãŒã‚ã‚‹ãªã‚‰ "cuda"
        compute_type="float32" # ç²¾åº¦é‡è¦–
    )
    print("âœ… ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†")

    audio_files = [
        f for f in os.listdir(folder_path)
        if f.lower().endswith((".mp3", ".wav", ".m4a", ".flac"))
    ]

    if not audio_files:
        print("âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return

    for audio_file in audio_files:
        audio_path = os.path.join(folder_path, audio_file)
        base_name = os.path.splitext(audio_file)[0]

        # === æ—¥æ™‚ä»˜ãƒãƒ³ãƒ‰ãƒ« ===
        now_str = datetime.now().strftime("%Y%m%d-%H%M")
        output_filename = f"{base_name}_{now_str}.txt"
        output_file = os.path.join(folder_path, output_filename)

        print(f"\nğŸµ å‡¦ç†é–‹å§‹: {audio_file}")

        start_time = time.time()

        # === æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ ===
        # vad_filter=Trueã«ã—ã¤ã¤ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ç·©ãè¨­å®šã—ã¦èªå°¾åˆ‡ã‚Œã‚’é˜²ã
        segments, info = model.transcribe(
            audio_path,
            language="ja",
            beam_size=5,
            temperature=0.0,
            condition_on_previous_text=True,
            vad_filter=True,          # ç„¡éŸ³ãƒ«ãƒ¼ãƒ—é˜²æ­¢ã®ãŸã‚ONã«ã™ã‚‹
            vad_parameters=VAD_PARAMS, # èªå°¾åˆ‡ã‚Œé˜²æ­¢ã®ãŸã‚ã®ç·©å’Œè¨­å®š
            no_speech_threshold=0.6,
            chunk_length=30,
        )

        results = []
        full_text = ""
        last_end_time = 0.0 # ç›´å‰ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®çµ‚äº†æ™‚é–“

        total_duration = info.duration
        total_chunks = int(total_duration // 30) + 1

        for segment in segments:
            text = segment.text.strip()
            
            # ===== ç„¡éŸ³åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ =====
            # ç¾åœ¨ã®é–‹å§‹æ™‚é–“ - ç›´å‰ã®çµ‚äº†æ™‚é–“ ãŒ è¨­å®šå€¤ã‚’è¶…ãˆã¦ã„ãŸã‚‰ã€Œç„¡éŸ³ã€ã‚’æŒ¿å…¥
            gap = segment.start - last_end_time
            if gap >= SILENCE_THRESHOLD:
                gap_start = format_timestamp(last_end_time)
                gap_end = format_timestamp(segment.start)
                results.append(f"[{gap_start} - {gap_end}] ï¼ˆç„¡éŸ³ï¼‰")
            # ==========================

            if text:
                start = format_timestamp(segment.start)
                end = format_timestamp(segment.end)
                results.append(f"[{start} - {end}] {text}")
                full_text += text + " "
            
            # æ¬¡ã®ãƒ«ãƒ¼ãƒ—ã®ãŸã‚ã«çµ‚äº†æ™‚é–“ã‚’æ›´æ–°
            last_end_time = segment.end

            # ===== é€²æ—è¨ˆç®— =====
            processed_sec = segment.end
            progress_ratio = processed_sec / total_duration if total_duration > 0 else 0
            progress_pct = progress_ratio * 100

            elapsed = time.time() - start_time
            if progress_ratio > 0:
                estimated_total = elapsed / progress_ratio
                remaining = estimated_total - elapsed
            else:
                remaining = 0

            current_chunk = int(processed_sec // 30) + 1

            print(
                f"â³ {progress_pct:6.2f}% | "
                f"ãƒãƒ£ãƒ³ã‚¯ {current_chunk}/{total_chunks} | "
                f"{format_timestamp(processed_sec)} / {format_timestamp(total_duration)} | "
                f"æ®‹ã‚Šç´„ {format_timestamp(remaining)}",
                end="\r",
                flush=True
            )
        
        # æœ€å¾Œã«ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ«å°¾ã¾ã§ç„¡éŸ³ãŒã‚ã‚‹å ´åˆã®å‡¦ç†
        if total_duration - last_end_time >= SILENCE_THRESHOLD:
             gap_start = format_timestamp(last_end_time)
             gap_end = format_timestamp(total_duration)
             results.append(f"[{gap_start} - {gap_end}] ï¼ˆç„¡éŸ³ï¼‰")

        print()  # æ”¹è¡Œï¼ˆé€²æ—è¡Œã®å¾Œï¼‰

        with open(output_file, "w", encoding="utf-8-sig") as f:
            f.write("=== æ–‡å­—èµ·ã“ã—çµæœ ===\n")
            f.write(f"ãƒ•ã‚¡ã‚¤ãƒ«å: {audio_file}\n")
            f.write(f"å‡¦ç†æ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ¤œå‡ºè¨€èª: {info.language}\n")
            f.write(f"éŸ³å£°é•·: {format_timestamp(total_duration)}\n\n")

            f.write("--- å…¨æ–‡ ---\n")
            f.write(full_text.strip() + "\n\n")

            f.write("--- ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ã ---\n")
            f.write("\n".join(results))

        print(f"âœ… å®Œäº†: {output_file}")

    print("\nğŸ“„ å…¨å‡¦ç†å®Œäº†")


if __name__ == "__main__":
    transcribe_mp3_files()