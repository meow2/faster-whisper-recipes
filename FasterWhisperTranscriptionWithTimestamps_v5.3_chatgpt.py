import os
import warnings
import time
from datetime import datetime
from faster_whisper import WhisperModel

warnings.filterwarnings("ignore")

# === è¨­å®šé …ç›® ===
SILENCE_THRESHOLD = 2.0  # ã“ã‚Œä»¥ä¸Šã®ç©ºç™½ãŒã‚ã‚Œã°ã€Œï¼ˆç„¡éŸ³ï¼‰ã€ã¨è¡¨ç¤ºã™ã‚‹ç§’æ•°
# =============

def format_timestamp(seconds):
    seconds = max(0, int(seconds))
    hours = seconds // 3600
    minutes = (seconds % 3600) // 60
    secs = seconds % 60
    if hours > 0:
        return f"{hours}:{minutes:02d}:{secs:02d}"
    else:
        return f"{minutes:02d}:{secs:02d}"

def transcribe_mp3_files():
    folder_path = os.path.dirname(os.path.abspath(__file__))

    print("ğŸ¤– faster-whisperãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
    model = WhisperModel(
        "medium",
        device="cpu",          
        compute_type="float32" 
    )
    print("âœ… ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†")

    audio_files = [
        f for f in os.listdir(folder_path)
        if f.lower().endswith((".mp3", ".wav", ".m4a", ".flac"))
    ]

    if not audio_files:
        print("âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return

    for audio_file in audio_files:
        audio_path = os.path.join(folder_path, audio_file)
        base_name = os.path.splitext(audio_file)[0]

        now_str = datetime.now().strftime("%Y%m%d-%H%M")
        output_filename = f"{base_name}_{now_str}.txt"
        output_file = os.path.join(folder_path, output_filename)

        print(f"\nğŸµ å‡¦ç†é–‹å§‹: {audio_file}")

        start_time = time.time()

        # === å¤‰æ›´ç‚¹1: vad_filter=False ã«æˆ»ã™ï¼ˆå–ã‚Šã“ã¼ã—é˜²æ­¢ã®ãŸã‚çµ¶å¯¾ï¼‰ ===
        # ãã®ä»£ã‚ã‚Šã€temperatureã‚„log_prob_thresholdã‚’èª¿æ•´ã—ã¦å¹»è¦šã‚’æŠ‘åˆ¶
        segments, info = model.transcribe(
            audio_path,
            language="ja",
            beam_size=5,
            temperature=[0.0, 0.2, 0.4], # ç¢ºä¿¡åº¦ãŒä½ã„æ™‚ã«å†è©¦è¡Œã•ã›ã‚‹
            condition_on_previous_text=False, # ã€é‡è¦ã€‘ãƒ«ãƒ¼ãƒ—é˜²æ­¢ã®ãŸã‚ã€Œå‰ã®æ–‡è„ˆã€ã¸ã®ä¾å­˜ã‚’åˆ‡ã‚‹
            vad_filter=False,            # ã€é‡è¦ã€‘å–ã‚Šã“ã¼ã—NGãªã®ã§ãƒ•ã‚£ãƒ«ã‚¿ã¯OFF
            no_speech_threshold=0.6,
            chunk_length=30,
        )

        results = []
        full_text = ""
        
        last_end_time = 0.0
        last_text = ""         # ç›´å‰ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨˜éŒ²ï¼ˆãƒ«ãƒ¼ãƒ—åˆ¤å®šç”¨ï¼‰
        repetition_count = 0   # ç¹°ã‚Šè¿”ã—å›æ•°

        total_duration = info.duration
        total_chunks = int(total_duration // 30) + 1

        for segment in segments:
            text = segment.text.strip()
            
            # === å¤‰æ›´ç‚¹2: ãƒ«ãƒ¼ãƒ—ï¼ˆå¹»è¦šï¼‰ã®å¼·åˆ¶ã‚«ãƒƒãƒˆ ===
            # ã¾ã£ãŸãåŒã˜æ–‡è¨€ãŒé€£ç¶šã—ãŸã‚‰ã€ãã‚Œã¯Whisperã®ãƒã‚°ï¼ˆå¹»è¦šï¼‰ã®å¯èƒ½æ€§ãŒé«˜ã„
            if text == last_text:
                repetition_count += 1
                # 2å›ç›®ã¾ã§ã¯è¨±å®¹ï¼ˆã€Œã¯ã„ã€‚ã¯ã„ã€‚ã€ãªã©ï¼‰ã€3å›ä»¥ä¸Šé€£ç¶šã—ãŸã‚‰ç„¡è¦–ã—ã¦ã‚¹ã‚­ãƒƒãƒ—
                if repetition_count >= 2:
                    continue 
            else:
                repetition_count = 0 # é•ã†æ–‡ç« ãŒæ¥ãŸã‚‰ã‚«ã‚¦ãƒ³ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ
            
            last_text = text # æ¯”è¼ƒç”¨ã«ç¾åœ¨ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜
            # ========================================

            # === ç„¡éŸ³åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ ===
            gap = segment.start - last_end_time
            if gap >= SILENCE_THRESHOLD:
                gap_start = format_timestamp(last_end_time)
                gap_end = format_timestamp(segment.start)
                results.append(f"[{gap_start} - {gap_end}] ï¼ˆç„¡éŸ³ï¼‰")
            
            if text:
                start = format_timestamp(segment.start)
                end = format_timestamp(segment.end)
                results.append(f"[{start} - {end}] {text}")
                full_text += text + " "
            
            last_end_time = segment.end

            # é€²æ—è¡¨ç¤º
            processed_sec = segment.end
            progress_ratio = processed_sec / total_duration if total_duration > 0 else 0
            progress_pct = progress_ratio * 100
            elapsed = time.time() - start_time
            remaining = (elapsed / progress_ratio - elapsed) if progress_ratio > 0 else 0
            current_chunk = int(processed_sec // 30) + 1

            print(
                f"â³ {progress_pct:6.2f}% | "
                f"ãƒãƒ£ãƒ³ã‚¯ {current_chunk}/{total_chunks} | "
                f"{format_timestamp(processed_sec)} / {format_timestamp(total_duration)} | "
                f"æ®‹ã‚Šç´„ {format_timestamp(remaining)}",
                end="\r",
                flush=True
            )
        
        # æœ«å°¾ã®ç„¡éŸ³åˆ¤å®š
        if total_duration - last_end_time >= SILENCE_THRESHOLD:
             gap_start = format_timestamp(last_end_time)
             gap_end = format_timestamp(total_duration)
             results.append(f"[{gap_start} - {gap_end}] ï¼ˆç„¡éŸ³ï¼‰")

        print()

        with open(output_file, "w", encoding="utf-8-sig") as f:
            f.write("=== æ–‡å­—èµ·ã“ã—çµæœ ===\n")
            f.write(f"ãƒ•ã‚¡ã‚¤ãƒ«å: {audio_file}\n")
            f.write(f"å‡¦ç†æ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"éŸ³å£°é•·: {format_timestamp(total_duration)}\n\n")

            f.write("--- å…¨æ–‡ ---\n")
            f.write(full_text.strip() + "\n\n")

            f.write("--- ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ã ---\n")
            f.write("\n".join(results))

        print(f"âœ… å®Œäº†: {output_file}")

    print("\nğŸ“„ å…¨å‡¦ç†å®Œäº†")

if __name__ == "__main__":
    transcribe_mp3_files()